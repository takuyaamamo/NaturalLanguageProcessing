{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### プログラムからSolrを検索できるように関数定義を行う"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import urllib.parse\n",
    "import urllib.request\n",
    "\n",
    "# 使用するSolrのURL\n",
    "solr_url = 'http://localhost:8983/solr'\n",
    "# build_openerはログインが必要なサイトのときに使用する\n",
    "opener = urllib.request.build_opener(urllib.request.ProxyHandler())\n",
    "\n",
    "# Solrにデータを登録する関数、引数dataは登録するdataをdictで指定\n",
    "def load(collection, data):\n",
    "    \n",
    "    # Solrのコアに対してデータを登録するリクエストを作成,collectionにはデータ登録先のコア名を指定している\n",
    "    url='{0}/{1}/update'.format(solr_url, collection)\n",
    "    # Requestインスタンスの作成,\n",
    "    req = urllib.request.Request(\n",
    "        url,\n",
    "        # dataをdumps()でutf-8にエンコード\n",
    "        data=json.dumps(data).encode('utf-8'),\n",
    "        headers={'content-type': 'application/json'})\n",
    "\n",
    "    # データの登録を実行\n",
    "    print(url)\n",
    "    # resでリクエストの返答を受け取る\n",
    "    with opener.open(req) as res:\n",
    "        # データ確認\n",
    "        print(res.read().decode('utf-8'))\n",
    "\n",
    "    # Solrのコアに対してコミット指示するリクエストを作成,collectionにはデータ登録先のコア名を指定している\n",
    "    url = '{0}/{1}/update?softCommit=true'.format(solr_url, collection)\n",
    "    # urlに対してリクエスト\n",
    "    req = urllib.request.Request(url)\n",
    "    # resuでリクエストの返答を受け取る、opnerはプロキシ環境変数に設定している場合も動くようにする為\n",
    "    with opener.open(req) as res:\n",
    "        # データを確認\n",
    "        print(res.read().decode('utf-8'))\n",
    "        \n",
    "# solrプログラムから検索を行う関数\n",
    "def search(keywords, rows=100):\n",
    "    # keywordsは2重のリストとなる。ためkeywordsをgroup、groupをkeywordに\n",
    "    query = ' AND '.join([\n",
    "        # 内側のリストは「OR検索したい語」のリスト\n",
    "        '(' + ' OR '.join([f'content_txt_ja:\"{keyword}\"' for keyword in group])\n",
    "        # 外側のリストは「AND検索したいグループ」のリスト\n",
    "        + ')' for group in keywords\n",
    "    ])\n",
    "    # 検索クエリの作成content_txt_jaフィールドを検索するクエリを作成する。\n",
    "    data = {\n",
    "        'q':     query,\n",
    "        'wt':    'json',\n",
    "        'rows':  rows,\n",
    "        'hl':    'on',\n",
    "        'hl.fl': 'content_txt_ja',\n",
    "    }\n",
    "    # 検索リクエストの作成（＊１）\n",
    "    req = urllib.request.Request(\n",
    "        # Solrでの検索APIは/select\n",
    "        url=f'{solr_url}/doc/select',\n",
    "        # JSON形式のデータをdataとして指定\n",
    "        data=urllib.parse.urlencode(data).encode('utf-8'),)\n",
    "    # 検索リクエストの実行（＊２）\n",
    "    with opener.open(req) as res:\n",
    "        # UTF-8のバイト列からUnicode文字列からなるstr型に変換し、JSON形式の文字列とみなしてdict型に変換したものを返す\n",
    "        return json.loads(res.read().decode('utf-8'))\n",
    "\n",
    "# アノテーションを見つける関数\n",
    "def search_annotation(fl_keyword_pairs, rows=100):\n",
    "    # fl_keyword_pairsは2重のリストとなる。ためfl_keyword_pairsをgroup、groupをkeywordに\n",
    "    query = ' AND '.join([\n",
    "        # 内側のリストは「OR検索したい語」のリスト\n",
    "        '(' + ' OR '.join([f'{fl}:\"{keyword}\"' for keyword in group])\n",
    "        # 外側のリストは「AND検索したいグループ」のリスト\n",
    "        + ')' for fl, keywords in fl_keyword_pairs\n",
    "            for group in keywords\n",
    "    ])\n",
    "    # 検索クエリの作成content_txt_jaフィールドを検索するクエリを作成する。\n",
    "    data = {\n",
    "        'q':     query,\n",
    "        'wt':    'json',\n",
    "        'rows':  rows,\n",
    "    }\n",
    "    # 検索リクエストの作成（＊１）\n",
    "    req = urllib.request.Request(\n",
    "        # Solrでの検索APIは/select\n",
    "        url=f'{solr_url}/anno/select',\n",
    "        # JSON形式のデータをdataとして指定\n",
    "        data=urllib.parse.urlencode(data).encode('utf-8'),)\n",
    "    # 検索リクエストの実行（＊２）\n",
    "    with opener.open(req) as res:\n",
    "        # UTF-8のバイト列からUnicode文字列からなるstr型に変換し、JSON形式の文字列とみなしてdict型に変換したものを返す\n",
    "        return json.loads(res.read().decode('utf-8'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solrへのアノテーションデータの登録"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Using _default configset with data driven schema functionality. NOT RECOMMENDED for production use.\n",
      "         To turn off: bin/solr config -c anno -p 8983 -action set-user-property -property update.autoCreateFields -value false\n",
      "\n",
      "Created new core 'anno'\n"
     ]
    }
   ],
   "source": [
    "# solrにコアを作成\n",
    "! ../solr-8.2.0/bin/solr create -c anno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# アノテーション関連のデータをannoに登録して、検索できるようにする。\n",
    "# アノテーションのリストであるxsの中からアノテーションyを含むものを1つ返す関数\n",
    "# 後にannoutil.pyに書き出し予定\n",
    "def find_x_including_y(xs, y):\n",
    "    for x in xs:\n",
    "    # アノテーション間の包含関係を扱う。指定したアノテーションを含む一文を取得する\n",
    "        if x['begin'] <= y['begin'] and y['end'] <= x['end']:\n",
    "            return x\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/usr/lib/python36.zip', '/usr/lib/python3.6', '/usr/lib/python3.6/lib-dynload', '', '/home/vagrant/.local/lib/python3.6/site-packages', '/usr/local/lib/python3.6/dist-packages', '/usr/lib/python3/dist-packages', '/home/vagrant/.local/lib/python3.6/site-packages/IPython/extensions', '/home/vagrant/.ipython']\n"
     ]
    }
   ],
   "source": [
    "# https://www.sejuku.net/blog/66459\n",
    "# システムに関する処理をまとめたライブラリのsysを読み込む\n",
    "import sys\n",
    "# 下記でライブラリを読み込めるパス一覧を表示できる。ここにパスを書き込むと異なる階層からライブラリを読み込む事が可能となる。\n",
    "print(sys.path)\n",
    "# sys.path.append(\"相対パス\")でsys.pathに追加、ここではディレクトリまでを指定する\n",
    "sys.path.append(\"src\")\n",
    "\n",
    "import sqlitedatastore as datastore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 文単位でSolrに登録\n",
    "def load_sentence():\n",
    "    data = []\n",
    "    # 全てのdoc_idを取得し回す\n",
    "    for doc_id in datastore.get_all_ids(limit=-1):\n",
    "        # 行の中からcontentとmeta_info部分を取り出す。dict型で帰ってくる\n",
    "        row = datastore.get(doc_id, ['content', 'meta_info'])\n",
    "        text = row['content']\n",
    "        meta_info = json.loads(row['meta_info'])\n",
    "        \n",
    "        for i, sent in enumerate(datastore.get_annotation(doc_id, 'sentence')):\n",
    "            # Solrへ登録するデータ構造へ変換する\n",
    "            data.append({\n",
    "                'id':               '{0:d}.{1:s}.{2:d}'.format(doc_id, 'sentence', i),\n",
    "                'doc_id_i':         doc_id,\n",
    "                # 以下2つはダイナミックフィールド\n",
    "                'anno_id_i':        i,# アノテーションの通し番号\n",
    "                'name_s':           'sentence',# アノテーション名\n",
    "                'sentence_txt_ja':  text[sent['begin']:sent['end']],\n",
    "                'title_txt_ja':     meta_info['title'],\n",
    "                'url_s':            meta_info['url'],\n",
    "            })\n",
    "    \n",
    "    # Solrへ登録\n",
    "    load('anno', data)\n",
    "\n",
    "    \n",
    "# affiliationアノテーションで検索できるようにSolrに登録\n",
    "def load_affiliation():\n",
    "    anno_name = 'affiliation'\n",
    "    data = []\n",
    "    # 全てのdoc_idを取得し回す\n",
    "    for doc_id in datastore.get_all_ids(limit=-1):\n",
    "        # 行の中からcontentとmeta_info部分を取り出す。dict型で帰ってくる\n",
    "        row = datastore.get(doc_id, ['content', 'meta_info'])\n",
    "        text = row['content']\n",
    "        meta_info = json.loads(row['meta_info'])\n",
    "        sents = datastore.get_annotation(doc_id, 'sentence')\n",
    "        \n",
    "        # sentenceとaffiliationのアノテーションを取得し、affiliationの方でforを回す。\n",
    "        for i, anno in enumerate(datastore.get_annotation(doc_id, anno_name)):\n",
    "            # Solrへ登録するデータ構造へ変換する\n",
    "            # アノテーションを含んでいるものを返し含まないものはNoneとする\n",
    "            sent = find_x_including_y(sents, anno)\n",
    "            data.append({\n",
    "                'id':               f'{doc_id:d}.{anno_name:s}.{i:d}',\n",
    "                'doc_id_i':         doc_id,\n",
    "                # 以下2つはダイナミックフィールド\n",
    "                'anno_id_i':        i,# アノテーションの通し番号\n",
    "                'name_s':           'anno_name',# アノテーション名\n",
    "                'sentence_txt_ja':  text[sent['begin']:sent['end']],\n",
    "                anno_name + '_txt_ja': text[anno['begin']:anno['end']],# affiliationのアノテーションがついたテキストを格納\n",
    "                'title_txt_ja':     meta_info['title'],\n",
    "                'url_s':            meta_info['url'],\n",
    "            })\n",
    "    \n",
    "    # Solrへ登録\n",
    "    load('anno', data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 実行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://localhost:8983/solr/anno/update\n",
      "{\n",
      "  \"responseHeader\":{\n",
      "    \"status\":0,\n",
      "    \"QTime\":4961}}\n",
      "\n",
      "{\n",
      "  \"responseHeader\":{\n",
      "    \"status\":0,\n",
      "    \"QTime\":839}}\n",
      "\n",
      "http://localhost:8983/solr/anno/update\n",
      "{\n",
      "  \"responseHeader\":{\n",
      "    \"status\":0,\n",
      "    \"QTime\":78}}\n",
      "\n",
      "{\n",
      "  \"responseHeader\":{\n",
      "    \"status\":0,\n",
      "    \"QTime\":42}}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "datastore.connect()\n",
    "load_sentence()\n",
    "load_affiliation()\n",
    "datastore.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
