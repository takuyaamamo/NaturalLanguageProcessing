{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDFを計算する\n",
    "文書中に含まれる単語の重要度を評価する手法\n",
    "$$\n",
    "\\begin{eqnarray}\n",
    "\\mathrm{tf}-\\mathrm{idf}(w, d) &=& \\mathrm{tf}(w, d) \\times \\mathrm{idf}(w)\\\\\n",
    "                               &=& 単語wの文書d中での出現回数 \\times \\log \\displaystyle \\frac{全文書数}{単語wが出現する文書数} \n",
    "                               \\end{eqnarray}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sklearn\n",
      "  Downloading https://files.pythonhosted.org/packages/1e/7a/dbb3be0ce9bd5c8b7e3d87328e79063f8b263b2b1bfa4774cb1147bfcd3f/sklearn-0.0.tar.gz\n",
      "Collecting scikit-learn (from sklearn)\n",
      "  Downloading https://files.pythonhosted.org/packages/a0/c5/d2238762d780dde84a20b8c761f563fe882b88c5a5fb03c056547c442a19/scikit_learn-0.21.3-cp36-cp36m-manylinux1_x86_64.whl (6.7MB)\n",
      "\u001b[K    100% |████████████████████████████████| 6.7MB 149kB/s ta 0:00:01  0% |                                | 20kB 98kB/s eta 0:01:08\n",
      "\u001b[?25hCollecting scipy>=0.17.0 (from scikit-learn->sklearn)\n",
      "  Downloading https://files.pythonhosted.org/packages/29/50/a552a5aff252ae915f522e44642bb49a7b7b31677f9580cfd11bcc869976/scipy-1.3.1-cp36-cp36m-manylinux1_x86_64.whl (25.2MB)\n",
      "\u001b[K    100% |████████████████████████████████| 25.2MB 48kB/s eta 0:00:01   23% |███████▋                        | 6.0MB 315kB/s eta 0:01:01    41% |█████████████▏                  | 10.3MB 367kB/s eta 0:00:41\n",
      "\u001b[?25hCollecting joblib>=0.11 (from scikit-learn->sklearn)\n",
      "  Downloading https://files.pythonhosted.org/packages/cd/c1/50a758e8247561e58cb87305b1e90b171b8c767b15b12a1734001f41d356/joblib-0.13.2-py2.py3-none-any.whl (278kB)\n",
      "\u001b[K    99% |███████████████████████████████▊| 276kB 180kB/s eta 0:00:01    100% |████████████████████████████████| 286kB 198kB/s \n",
      "\u001b[?25hCollecting numpy>=1.11.0 (from scikit-learn->sklearn)\n",
      "  Downloading https://files.pythonhosted.org/packages/e5/e6/c3fdc53aed9fa19d6ff3abf97dfad768ae3afce1b7431f7500000816bda5/numpy-1.17.2-cp36-cp36m-manylinux1_x86_64.whl (20.4MB)\n",
      "\u001b[K    100% |████████████████████████████████| 20.4MB 79kB/s eta 0:00:01\n",
      "\u001b[?25hBuilding wheels for collected packages: sklearn\n",
      "  Running setup.py bdist_wheel for sklearn ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /home/vagrant/.cache/pip/wheels/76/03/bb/589d421d27431bcd2c6da284d5f2286c8e3b2ea3cf1594c074\n",
      "Successfully built sklearn\n",
      "Installing collected packages: numpy, scipy, joblib, scikit-learn, sklearn\n",
      "Successfully installed joblib-0.13.2 numpy-1.17.2 scikit-learn-0.21.3 scipy-1.3.1 sklearn-0.0\n"
     ]
    }
   ],
   "source": [
    "# !pip3 install sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SQlite用関数定義"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "import sqlite3\n",
    "\n",
    "conn = None\n",
    "\n",
    "\n",
    "def connect():\n",
    "    global conn\n",
    "    conn = sqlite3.connect('./sample.db')\n",
    "\n",
    "\n",
    "def close():\n",
    "    conn.close()\n",
    "\n",
    "\n",
    "def create_table():\n",
    "    conn.execute('DROP TABLE IF EXISTS docs')\n",
    "    conn.execute('''CREATE TABLE docs (\n",
    "            id          INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "            content     TEXT,\n",
    "            meta_info   BLOB,\n",
    "            sentence    BLOB,\n",
    "            chunk       BLOB,\n",
    "            token       BLOB\n",
    "        )''')\n",
    "\n",
    "\n",
    "def load(values):\n",
    "    conn.executemany(\n",
    "        'INSERT INTO docs (content, meta_info) VALUES (?,?)',\n",
    "        values)\n",
    "    conn.commit()\n",
    "\n",
    "\n",
    "def get(doc_id, fl):\n",
    "    row_ls = conn.execute(\n",
    "        'SELECT {} FROM docs WHERE id = ?'.format(','.join(fl)),\n",
    "        (doc_id,)).fetchone()\n",
    "    row_dict = {}\n",
    "    for key, value in zip(fl, row_ls):\n",
    "        row_dict[key] = value\n",
    "    return row_dict\n",
    "\n",
    "\n",
    "def get_all_ids(limit, offset=0):\n",
    "    return [record[0] for record in\n",
    "            conn.execute(\n",
    "        'SELECT id FROM docs LIMIT ? OFFSET ?',\n",
    "        (limit, offset))]\n",
    "\n",
    "\n",
    "def set_annotation(doc_id, name, value):\n",
    "    conn.execute(\n",
    "        'UPDATE docs SET {0} = ? where id = ?'.format(name),\n",
    "        (json.dumps(value), doc_id))\n",
    "    conn.commit()\n",
    "\n",
    "\n",
    "def get_annotation(doc_id, name):\n",
    "    row = conn.execute(\n",
    "        'SELECT {0} FROM docs WHERE id = ?'.format(name),\n",
    "        (doc_id,)).fetchone()\n",
    "    if row[0] is not None:\n",
    "        return json.loads(row[0])\n",
    "    else:\n",
    "        return []"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
